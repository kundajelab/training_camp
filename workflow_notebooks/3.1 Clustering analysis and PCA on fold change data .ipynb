{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Clustering analysis and PCA (on normalized fold change data)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Please make sure that you are using the R kernel to run this notebook.###\n",
    "We are now switching from the bash kernel to the R kernel. \n",
    "The R language provides a number of utilities for genomic data analysis and visualization. We will explore some of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The preprocessCore library provides a number of functions useful for statistical analysis,\n",
    "#including functions for data normalization that we will use below. \n",
    "library(\"preprocessCore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to your $WORK_DIR. The syntax for switching directories in R is a little different than what we used in bash. \n",
    "#Use the \"setwd\" command to switch to your $WORK_DIR \n",
    "sunetid=\"annashch\"\n",
    "work_dir=paste(\"/scratch/\",sunetid,sep=\"\")\n",
    "setwd(work_dir)\n",
    "#The \"dir\" command will list all files in your current working directory \n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will focus on the clustering and PCA analysis steps of the pipeline: \n",
    "![Analysis pipeline](images/part3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the fc signal matrix. You can either use the one you generated in the last tutorial,or the one that we have \n",
    "#pre-generated in the $AGGREGATE_ANALYSIS_DIR folder in case you ran into any issues with that step\n",
    "\n",
    "#fc_data=read.table(\"all.fc.txt\",header=TRUE)\n",
    "fc_data=read.table(\"/outputs/all.fc.txt\",header=TRUE)\n",
    "\n",
    "rownames(fc_data)=paste(fc_data$Chrom,fc_data$Start,fc_data$End,sep='\\t')\n",
    "#remove the columns we will not use in downstream analysis\n",
    "fc_data$ID=NULL\n",
    "fc_data$Chrom=NULL\n",
    "fc_data$Start=NULL\n",
    "fc_data$End=NULL\n",
    "\n",
    "head(fc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data \n",
    "#quantile normalization \n",
    "norm_asinh_fc=normalize.quantiles(data.matrix(asinh(fc_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(norm_asinh_fc)=names(fc_data)\n",
    "rownames(norm_asinh_fc)=rownames(fc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(norm_asinh_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! After quantile normalization, the fold change values across samples are on the same scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) is a way to identify the primary directions of variation in the data. It can also be used for very coarse-grained clustering of samples; similar samples will have similar coordinates along the principal axes.\n",
    "\n",
    "We will perform PCA on *all.fc.txt*. We treat each sample as a single point in a very high dimensional space (where the dimensionality is equal to the number of genes the vary), and then we will perform dimensionality reduction in this space. We can color-code the PCA plots by \"Strain\", \"Timepoint\", \"Researcher\", or \"Sample\" to determine which parameter separates the samples most effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We run the principle component analysis command in R\n",
    "\n",
    "#The t() function transposes the data matrix and allows us to cluster the samples, as opposed to the individual peaks,\n",
    "#by placing the samples in the rows and the peaks in the columns. \n",
    "fc.pca=prcomp(t(norm_asinh_fc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a scree plot that shows how much variance in the data is explained by each prinicipal component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained=round(100*fc.pca$sdev^2/sum(fc.pca$sdev^2),2)\n",
    "print(var_explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a simple bar graph to better illustrate the variance explained by each PC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot(var_explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the first few prinicpal components to see if they correlate with any of our experimental variables: \n",
    "\n",
    "    * Strain of yeast \n",
    "    * Timepoint \n",
    "    \n",
    "We also expect replicates for the same sample to cluster closely together.\n",
    "\n",
    "Finally, we should make sure to check for any unintended batch effects in the data. For example, it's posssible that samples generated by one researcher may exhibit a systematic difference from samples generated by a different researcher. We should check for this bias and correct it if possible. \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=read.table(\"/metadata/TC2019_samples.tsv\",header=TRUE)\n",
    "nrow(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we load our metadata file into R to help us color samples by replicate, strain, timepoint, and researcher. \n",
    "metadata=read.table(\"/metadata/TC2019_samples.tsv\",header=TRUE)\n",
    "#We use the \"factor\" function to tell R which variables are categorical rather than continuous \n",
    "metadata$Strain=factor(metadata$Strain)\n",
    "metadata$Timepoint=factor(metadata$Timepoint)\n",
    "metadata$Sample=factor(metadata$Sample)\n",
    "metadata$Researcher=factor(metadata$Researcher)\n",
    "metadata$Group=factor(metadata$Group)\n",
    "head(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the PC columns from the fc.pca object \n",
    "pcs=data.frame(fc.pca$x)\n",
    "head(pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns from the metadata file. Do this safely using the \"merge\" command to make sure the sample ID's \n",
    "#from the two data frames are aligned\n",
    "pcs$ID=rownames(pcs)\n",
    "pcs_annotated=merge(pcs,metadata,by=\"ID\")\n",
    "head(pcs_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the ggplot package in R to generate scatterplots of PC1 vs PC2, PC2 vs PC3, etc and color-code\n",
    "by experimental variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 20 distinct colors to use for the PCA scatterplot. \n",
    "cols=c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a','#ffff99','#b15928','#8dd3c7','#ffffb3','#bebada','#fb8072','#80b1d3','#fdb462','#b3de69','#fccde5','#d9d9d9','#bc80bd','#ccebc5','#ffed6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pc1 vs pc2, color by Sample -- that is, all replicates for the same sample should be the same color. \n",
    "ggplot(data=pcs_annotated,\n",
    "       aes(x=PC1,y=PC2,color=Sample))+\n",
    "       geom_point(size=3)+\n",
    "       scale_color_manual(values=cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see replicates of the same sample clustering close together. Do we see this in the scatterplot above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pc1 vs pc2, color by Strain \n",
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Strain))+\n",
    "geom_point(size=3)+\n",
    "scale_color_manual(values=cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear clustering by strain is observed. Let's color by Timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Timepoint,label=ID))+\n",
    "geom_point()+\n",
    "geom_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting for batch effects ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for batch effects from Researcher and Group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pc1 vs pc2, color by Researcher -- here, we're checking for a batch effect based on researcher.\n",
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Researcher))+\n",
    "geom_point(size=3)+\n",
    "scale_color_manual(values=cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pc1 vs pc2, color by Researcher -- here, we're checking for a batch effect based on researcher.\n",
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Group))+\n",
    "geom_point(size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see a clear batch effect for any individual researcher, but we do observe a batch effect from the Kundaje lab members' samples. In this case, unfortunately we cannot correct for the \"Group\" batch effect, as the design is confounded for the \"Group\" variable. However, we can try to correct for any \"Researcher\" batch effect, even though it's not 100% clear if there is one.  We use the R **limma** package to fit a linear mixed effects model. The explanatory variables are Strain, Timepoint, and  Group. The output variable is the normalized fold change value in the data matrix. We then subtract out the contribution from \"Group\" (the confounding variable) to the output variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(limma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the row order of the metadata file matches the column order of the fc_data_matrix file. \n",
    "rownames(metadata)=metadata$ID\n",
    "metadata=metadata[colnames(norm_asinh_fc),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design the model using entries from our metadata file \n",
    "mod=model.matrix(~0+Strain +Timepoint+Researcher,data=metadata)\n",
    "\n",
    "#fit the model to the data \n",
    "fit=lmFit(norm_asinh_fc,design=mod)\n",
    "\n",
    "head(coefficients(fit))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(fit$design)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We note that column 5 in the model captures the batch effect from the \"Researcher\" variable. We can remove the \n",
    "#contribution of this variable from the data: \n",
    "batch_contribution=coefficients(fit)[,12:29]%*% t(fit$design[,12:29])\n",
    "norm_asinh_fc_corrected=norm_asinh_fc-batch_contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-run the PCA analysis on  fc_data_matrix_corrected to make sure we're no longer observing a batch effect \n",
    "due to researcher.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.pca.corrected=prcomp(t(norm_asinh_fc_corrected))\n",
    "var_explained=round(100*fc.pca.corrected$sdev^2/sum(fc.pca.corrected$sdev^2),2)\n",
    "barplot(var_explained)\n",
    "pcs.corrected=data.frame(fc.pca.corrected$x)\n",
    "pcs.corrected$ID=rownames(pcs.corrected)\n",
    "pcs_annotated.corrected=merge(pcs.corrected,metadata,by=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,\n",
    "       aes(x=PC1,y=PC2,color=Researcher))+\n",
    "       geom_point(size=3)+\n",
    "       scale_color_manual(values=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,\n",
    "       aes(x=PC1,y=PC2,color=Group))+\n",
    "       geom_point(size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We no longer see the Kundaje lab samples clustering together. Let's make sure that the samples still separate by Timepoint and check for any improved separation by Strain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,aes(x=PC1,y=PC2,color=Timepoint))+\n",
    "geom_point(size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for separation by Strain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,aes(x=PC1,y=PC2,color=Strain))+\n",
    "geom_point(size=3)+\n",
    "scale_color_manual(values=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,aes(x=PC1,y=PC3,color=Strain))+\n",
    "geom_point(size=3)+\n",
    "scale_color_manual(values=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=ebayes(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(fit$df.residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting peak contributions to principal components. ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'd like to determine how much each peak contributes to PC1, PC2, and PC3. We can look at PC4 and up also, but for the sake of time we'll stick with the first 3 principal components; from the scree plot, we see they explain approximately 50% of the variance in the data. Primarily we want to get a sense of which peaks are critical in defining the principle components, and in which direction (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contribs_pc1=sort(fc.pca.corrected$rotation[,1])\n",
    "contribs_pc2=sort(fc.pca.corrected$rotation[,2])\n",
    "contribs_pc3=sort(fc.pca.corrected$rotation[,3])\n",
    "\n",
    "#these are lists of contributs from each peak to the corresponding PC\n",
    "tail(contribs_pc1)\n",
    "length(contribs_pc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the write.table command to write the PC contribution data to output files. \n",
    "\n",
    "write.table(contribs_pc1,paste(work_dir,\"pc1_contribs.txt\",sep='/'),quote=FALSE,col.names=FALSE,row.names=TRUE,sep='\\t')\n",
    "write.table(contribs_pc2,paste(work_dir,\"pc2_contribs.txt\",sep='/'),quote=FALSE,col.names=FALSE,row.names=TRUE,sep='\\t')\n",
    "write.table(contribs_pc3,paste(work_dir,\"pc3_contribs.txt\",sep='/'),quote=FALSE,col.names=FALSE,row.names=TRUE,sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering of Fold Change Signal Across Samples ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster analysis is a simple way to visualize patterns in the data. By clustering peaks according to their signal across different time points, we may find groups of peaks that have similar behavior across these time points. By clustering samples according to their signal across peaks, we can perform a simple sanity check of data quality ‚Äê samples of the same time point should cluster together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gplots)\n",
    "library(RColorBrewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?hclust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by clustering normalized fold change data that has not been corrected for the sample swap or the batch effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.2(norm_asinh_fc,\n",
    "          scale     = \"none\",\n",
    "          col       = rev(colorRampPalette(brewer.pal(10, \"RdBu\"))(256)),\n",
    "          distfun   = function(x) dist(x,method=\"euclidean\"),\n",
    "          hclustfun = function(x) hclust(x, method=\"ward.D\"),\n",
    "          Rowv=TRUE,\n",
    "          Colv=TRUE,\n",
    "          trace=\"none\",\n",
    "          cexCol = 0.9,\n",
    "          margins=c(15,5),\n",
    "          labRow=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we examine the hierarchical clustering on the corrected fold change data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.2(norm_asinh_fc_corrected,\n",
    "          scale     = \"none\",\n",
    "          col       = rev(colorRampPalette(brewer.pal(10, \"RdBu\"))(256)),\n",
    "          distfun   = function(x) dist(x,method=\"euclidean\"),\n",
    "          hclustfun = function(x) hclust(x, method=\"ward.D\"),\n",
    "          Rowv=TRUE,\n",
    "          Colv=TRUE,\n",
    "          trace=\"none\",\n",
    "          cexCol = 0.9,\n",
    "          margins=c(15,5),\n",
    "          labRow=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very little contrast in the heatmap that was generated. We can add contrast by modifying how \"breaks\" between colors are generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We split the fold change matrix into 1% quantiles \n",
    "quantile.range <- quantile(norm_asinh_fc_corrected, probs = seq(0, 1, 0.01))\n",
    "#we scale the breaks in the heatmap color palette according to the quantiles. \n",
    "palette.breaks <- seq(quantile.range[\"5%\"], quantile.range[\"95%\"], 0.1)\n",
    "\n",
    "\n",
    "heatmap.2(norm_asinh_fc_corrected,\n",
    "          scale     = \"none\",\n",
    "          col       = rev(colorRampPalette(brewer.pal(10, \"RdBu\"))(length(palette.breaks) - 1)),\n",
    "          distfun   = function(x) dist(x,method=\"euclidean\"),\n",
    "          hclustfun = function(x) hclust(x, method=\"ward.D\"),\n",
    "          Rowv=TRUE,\n",
    "          Colv=TRUE,\n",
    "          trace=\"none\",\n",
    "          cexCol = 0.9,\n",
    "          margins=c(15,5),\n",
    "          breaks = palette.breaks,\n",
    "          labRow=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two heatmaps look very different, but show the same data! \n",
    "When selecting a color scheme for PCA or heatmaps in R, the R Color Brewer tool is quite useful. Also, for nice color palettes, check out: http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
