{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequencing data analysis\n",
    "\n",
    "### IMPORTANT: Please make sure that your are using the bash kernel to run this notebook.\n",
    "### IMPORTANT: Run the command below to git pull and make sure you are running the latest code!! ###\n",
    "#### (Do this at the beginning of every session) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd /srv/scratch/training_camp/tc2017/`whoami`/src/training_camp\n",
    "git stash \n",
    "git pull "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook covers analysis of DNA sequencing data from raw files to processed signals.\n",
    "\n",
    "Although this analysis is for ATAC-seq data, many of the steps (especially the first section) are the same for other types of DNA sequencing experiments.\n",
    "\n",
    "We'll be doing the analysis in Bash, which is the standard language for UNIX command-line scripting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps in the analysis pipeline that are covered in this notebook are indicated below:\n",
    "![Sequencing Data Analysis 1](part1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting up the data\n",
    "\n",
    "We start with raw `.fastq.gz` files, which are provided by the sequencing instrument. For each DNA molecule (read) that was sequenced, they provide the nucleotide sequence, and information about the quality of the signal of that nucleotide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "### Set up variables storing the location of our data\n",
    "### The proper way to load your variables is with the ~/.bashrc command, but this is very slow in iPython \n",
    "export SUNETID=\"$(whoami)\"\n",
    "export WORK_DIR=\"/srv/scratch/training_camp/tc2017/${SUNETID}\"\n",
    "export DATA_DIR=\"${WORK_DIR}/data\"\n",
    "export FASTQ_DIR=\"${DATA_DIR}/fastq/\"\n",
    "export SRC_DIR=\"${WORK_DIR}/src/training_camp/src/\"\n",
    "export ANALYSIS_DIR=\"${WORK_DIR}/analysis/\"\n",
    "export YEAST_DIR=\"/srv/scratch/training_camp/saccer3/seq\"\n",
    "export YEAST_INDEX=\"/srv/scratch/training_camp/saccer3/bowtie2_index/saccer3\"\n",
    "export YEAST_CHR=\"/srv/scratch/training_camp/saccer3/sacCer3.chrom.sizes\"\n",
    "export TMP=\"${WORK_DIR}/tmp\"\n",
    "export TEMP=$TMP \n",
    "export TMPDIR=$TMP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check exactly which fastqs we have:\n",
    "\n",
    "(recall that the `ls` command lists the contents of a directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT-SCD-0_6MNaCl-Rep1_R1_001.fastq.gz\tcln3-SCD-Rep1_R2_001.fastq.gz\r\n",
      "WT-SCD-0_6MNaCl-Rep1_R2_001.fastq.gz\tcln3-SCD-Rep2_R1_001.fastq.gz\r\n",
      "WT-SCD-0_6MNaCl-Rep2_R1_001.fastq.gz\tcln3-SCD-Rep2_R2_001.fastq.gz\r\n",
      "WT-SCD-0_6MNaCl-Rep2_R2_001.fastq.gz\tcln3-SCE-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "WT-SCD-Rep1_R1_001.fastq.gz\t\tcln3-SCE-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "WT-SCD-Rep1_R2_001.fastq.gz\t\tcln3-SCE-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "WT-SCD-Rep2_R1_001.fastq.gz\t\tcln3-SCE-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "WT-SCD-Rep2_R2_001.fastq.gz\t\tcln3-SCE-Rep1_R1_001.fastq.gz\r\n",
      "WT-SCE-0_6MNaCl-Rep1_R1_001.fastq.gz\tcln3-SCE-Rep1_R2_001.fastq.gz\r\n",
      "WT-SCE-0_6MNaCl-Rep1_R2_001.fastq.gz\tcln3-SCE-Rep2_R1_001.fastq.gz\r\n",
      "WT-SCE-0_6MNaCl-Rep2_R1_001.fastq.gz\tcln3-SCE-Rep2_R2_001.fastq.gz\r\n",
      "WT-SCE-0_6MNaCl-Rep2_R2_001.fastq.gz\ttrim.sh\r\n",
      "WT-SCE-Rep1_R1_001.fastq.gz\t\ttrim.sh~\r\n",
      "WT-SCE-Rep1_R2_001.fastq.gz\t\twhi5-SCE-Rep1_R1_001.fastq.gz\r\n",
      "WT-SCE-Rep2_R1_001.fastq.gz\t\twhi5-SCE-Rep1_R2_001.fastq.gz\r\n",
      "WT-SCE-Rep2_R2_001.fastq.gz\t\twhi5-SCE-Rep2_R1_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep1_R1_001.fastq.gz\twhi5-SCE-Rep2_R2_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep1_R2_001.fastq.gz\twhi5-cln3-SCE-Rep1_R1_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep2_R1_001.fastq.gz\twhi5-cln3-SCE-Rep1_R2_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep2_R2_001.fastq.gz\twhi5-cln3-SCE-Rep2_R1_001.fastq.gz\r\n",
      "cln3-SCD-Rep1_R1_001.fastq.gz\t\twhi5-cln3-SCE-Rep2_R2_001.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls $FASTQ_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As a sanity check, we can also look at the size and last edited time of some of the fastqs by addind `-lrth` to the `ls` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.4G\r\n",
      "-rwxrwxr-x 1 user1 user1  81M Sep 21 17:07 WT-SCD-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1  73M Sep 21 17:07 WT-SCD-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1 159M Sep 21 17:07 WT-SCD-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1 150M Sep 21 17:07 WT-SCD-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1  32M Sep 21 17:07 WT-SCD-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1  28M Sep 21 17:07 WT-SCD-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1 168M Sep 21 17:07 WT-SCD-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1 157M Sep 21 17:07 WT-SCD-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 user1 user1 203M Sep 21 17:07 WT-SCE-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls -lrth $FASTQ_DIR | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the format of one of the fastqs. Notice that each read takes up 4 lines:\n",
    "1. the read name\n",
    "2. the read's nucleotide sequence\n",
    "3. a '+' to indicate the record contains another line\n",
    "4. a quality score for each base (a number encoded as a letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NS500418:691:HTFJ7AFXX:1:11101:11481:1060 1:N:0:AAGAGGCA+GCGATCTA\r\n",
      "CTAAGAAGTGGATAACCAGCAAATGCTAGCACCACTATTTAGTAGGTTAAGGTCTCGTTCGTTATCGCAATTAAGC\r\n",
      "+\r\n",
      "AAAAAEEEEEEEEAEEEEEEEEEEEEE/EE/EEEEEEEEEEEEEEEEEEEEEEEEEEEEAEAEEEEEEEEEEA/EA\r\n",
      "@NS500418:691:HTFJ7AFXX:1:11101:12189:1060 1:N:0:AAGAGGCA+GCGATCTA\r\n",
      "CCTTCACCCAGGTAGGATAAGGATCAGGCGGAGCGACAGTATTAACAACAACTCGAGAAAAAACGATACATATACT\r\n",
      "+\r\n",
      "AAAAAEAEEAAE/EEEEEEEEEEEAEEAEAEEEAEAEA/EEEAEAEEEEA/EE<EAE/EEEA/AE//EAEEEEEAE\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "zcat $(ls $FASTQ_DIR* | head -n 1) | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Adapter trimming\n",
    "\n",
    "- In many kinds of DNA and RNA sequencing experiments, sometimes the sequences will read through the targeted sequence insert and into sequencing adapter or PCR primer sequences on the end of the fragment. When the insert size is shorter than the read length (like in some of our ATAC-seq reads), the adapter sequence is read by the sequencer.\n",
    "\n",
    "- We need to remove such adapter sequences because they won't align to the genome.\n",
    "\n",
    "- In ATAC-seq (the data we're analyzing), the fragment length follows a periodic distribution. Some reads have very short inserts (only a few basepairs), while other reads have inserts that are much longer (100's of basepairs — much longer than the 77bp reads we're using to read them.\n",
    "\n",
    "- We know ahead of time that the first part of the adapter sequence is `CTGTCTCTTATA`, since our reads are sequenced using a Nextera sample prep kit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19440\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# Let's sanity check our adapter sequence by seeing\n",
    "# how many times it occurs in the first 100000 reads.\n",
    "\n",
    "ADAPTER=\"CTGTCTCTTATA\"\n",
    "\n",
    "NUM_LINES=400000  # 4 * num_reads, since each fastq entry is 4 lines\n",
    "\n",
    "zcat $(ls $FASTQ_DIR*R1* | head -n 1) | head -n $NUM_LINES | grep $ADAPTER | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# Let's also check how often a permutation (rearrangement)\n",
    "# of the adapter sequence occurs:\n",
    "\n",
    "NOT_ADAPTER=\"CGTTCTTCTATA\"  # A permutation of the adapter sequence\n",
    "\n",
    "zcat $(ls $FASTQ_DIR*R1* | head -n 1) | head -n $NUM_LINES | grep $NOT_ADAPTER | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the correct adapter sequence occurs *many* times more in the reads than a permutation of the adapter sequene — this is an important validation that we have the right sequence.\n",
    "\n",
    "Now, we'll trim the paired-end reads using a tool called `cutadapt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#create a directory to store the trimmed data \n",
    "export TRIMMED_DIR=\"$ANALYSIS_DIR/trimmed/\"\n",
    "[[ ! -d $TRIMMED_DIR ]] && mkdir -p \"$TRIMMED_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for R1_fastq in ${FASTQ_DIR}*_R1*fastq.gz; do\n",
    "    \n",
    "    # Get the read 2 fastq file from the filename of read 1\n",
    "    R2_fastq=$(echo $R1_fastq | sed -e 's/R1/R2/')\n",
    "    \n",
    "    # Generate names for the trimmed fastq files\n",
    "\n",
    "    trimmed_R1_fastq=$TRIMMED_DIR$(echo $(basename $R1_fastq)| sed -e 's/.fastq.gz/.trimmed.fastq.gz/')\n",
    "    trimmed_R2_fastq=$TRIMMED_DIR$(echo $(basename $R2_fastq)| sed -e 's/.fastq.gz/.trimmed.fastq.gz/')   \n",
    "    echo cutadapt -m 5 -e 0.20 -a CTGTCTCTTATA -A CTGTCTCTTATA \\\n",
    "        -o ${trimmed_R1_fastq} \\\n",
    "        -p ${trimmed_R2_fastq} \\\n",
    "        $R1_fastq \\\n",
    "        $R2_fastq\n",
    "    cutadapt -m 5 -e 0.20 -a CTGTCTCTTATA -A CTGTCTCTTATA \\\n",
    "        -o ${trimmed_R1_fastq} \\\n",
    "        -p ${trimmed_R2_fastq} \\\n",
    "        $R1_fastq \\\n",
    "        $R2_fastq\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 3: Alignment\n",
    "\n",
    "Now, we're ready to align our trimmed reads to the Yeast SacCer3 reference genome.\n",
    "\n",
    "We'll use [Bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml), which is a [Burrows-Wheeler](https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform) based spliced aligner.\n",
    "\n",
    "Bowtie2 outputs a SAM (Sequence Alignment Map) file, which is a standard text encoding. To save space, we'll use `samtools view -b` to encode the output as a binarized SAM file — a BAM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/training_camp/saccer3/bowtie2_index/saccer3\r\n"
     ]
    }
   ],
   "source": [
    "#set the bowtie index\n",
    "export bowtie_index=$YEAST_INDEX\n",
    "echo $bowtie_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#create a directory to store the aligned data \n",
    "export ALIGNMENT_DIR=\"$ANALYSIS_DIR/aligned/\"\n",
    "[[ ! -d $ALIGNMENT_DIR ]] && mkdir -p \"$ALIGNMENT_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "1508102 reads; of these:\r\n",
      "  1508102 (100.00%) were paired; of these:\r\n",
      "    73214 (4.85%) aligned concordantly 0 times\r\n",
      "    630015 (41.78%) aligned concordantly exactly 1 time\r\n",
      "    804873 (53.37%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    73214 pairs aligned concordantly 0 times; of these:\r\n",
      "      8601 (11.75%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    64613 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      129226 mates make up the pairs; of these:\r\n",
      "        90618 (70.12%) aligned 0 times\r\n",
      "        8547 (6.61%) aligned exactly 1 time\r\n",
      "        30061 (23.26%) aligned >1 times\r\n",
      "97.00% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "2998028 reads; of these:\r\n",
      "  2998028 (100.00%) were paired; of these:\r\n",
      "    152546 (5.09%) aligned concordantly 0 times\r\n",
      "    1522929 (50.80%) aligned concordantly exactly 1 time\r\n",
      "    1322553 (44.11%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    152546 pairs aligned concordantly 0 times; of these:\r\n",
      "      19173 (12.57%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    133373 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      266746 mates make up the pairs; of these:\r\n",
      "        204475 (76.66%) aligned 0 times\r\n",
      "        14991 (5.62%) aligned exactly 1 time\r\n",
      "        47280 (17.72%) aligned >1 times\r\n",
      "96.59% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "601214 reads; of these:\r\n",
      "  601214 (100.00%) were paired; of these:\r\n",
      "    65890 (10.96%) aligned concordantly 0 times\r\n",
      "    334444 (55.63%) aligned concordantly exactly 1 time\r\n",
      "    200880 (33.41%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    65890 pairs aligned concordantly 0 times; of these:\r\n",
      "      4962 (7.53%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    60928 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      121856 mates make up the pairs; of these:\r\n",
      "        110272 (90.49%) aligned 0 times\r\n",
      "        2826 (2.32%) aligned exactly 1 time\r\n",
      "        8758 (7.19%) aligned >1 times\r\n",
      "90.83% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "3274076 reads; of these:\r\n",
      "  3274076 (100.00%) were paired; of these:\r\n",
      "    249700 (7.63%) aligned concordantly 0 times\r\n",
      "    1902020 (58.09%) aligned concordantly exactly 1 time\r\n",
      "    1122356 (34.28%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    249700 pairs aligned concordantly 0 times; of these:\r\n",
      "      26069 (10.44%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    223631 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      447262 mates make up the pairs; of these:\r\n",
      "        377700 (84.45%) aligned 0 times\r\n",
      "        18447 (4.12%) aligned exactly 1 time\r\n",
      "        51115 (11.43%) aligned >1 times\r\n",
      "94.23% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "3876571 reads; of these:\r\n",
      "  3876571 (100.00%) were paired; of these:\r\n",
      "    270856 (6.99%) aligned concordantly 0 times\r\n",
      "    2324735 (59.97%) aligned concordantly exactly 1 time\r\n",
      "    1280980 (33.04%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    270856 pairs aligned concordantly 0 times; of these:\r\n",
      "      32846 (12.13%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    238010 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      476020 mates make up the pairs; of these:\r\n",
      "        400374 (84.11%) aligned 0 times\r\n",
      "        24033 (5.05%) aligned exactly 1 time\r\n",
      "        51613 (10.84%) aligned >1 times\r\n",
      "94.84% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "4131152 reads; of these:\r\n",
      "  4131152 (100.00%) were paired; of these:\r\n",
      "    257059 (6.22%) aligned concordantly 0 times\r\n",
      "    2505006 (60.64%) aligned concordantly exactly 1 time\r\n",
      "    1369087 (33.14%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    257059 pairs aligned concordantly 0 times; of these:\r\n",
      "      35727 (13.90%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    221332 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      442664 mates make up the pairs; of these:\r\n",
      "        357445 (80.75%) aligned 0 times\r\n",
      "        28149 (6.36%) aligned exactly 1 time\r\n",
      "        57070 (12.89%) aligned >1 times\r\n",
      "95.67% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "180410 reads; of these:\r\n",
      "  180410 (100.00%) were paired; of these:\r\n",
      "    11497 (6.37%) aligned concordantly 0 times\r\n",
      "    84956 (47.09%) aligned concordantly exactly 1 time\r\n",
      "    83957 (46.54%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    11497 pairs aligned concordantly 0 times; of these:\r\n",
      "      1779 (15.47%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    9718 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      19436 mates make up the pairs; of these:\r\n",
      "        14850 (76.40%) aligned 0 times\r\n",
      "        505 (2.60%) aligned exactly 1 time\r\n",
      "        4081 (21.00%) aligned >1 times\r\n",
      "95.88% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "4059565 reads; of these:\r\n",
      "  4059565 (100.00%) were paired; of these:\r\n",
      "    282359 (6.96%) aligned concordantly 0 times\r\n",
      "    2500637 (61.60%) aligned concordantly exactly 1 time\r\n",
      "    1276569 (31.45%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    282359 pairs aligned concordantly 0 times; of these:\r\n",
      "      35448 (12.55%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    246911 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      493822 mates make up the pairs; of these:\r\n",
      "        414767 (83.99%) aligned 0 times\r\n",
      "        26614 (5.39%) aligned exactly 1 time\r\n",
      "        52441 (10.62%) aligned >1 times\r\n",
      "94.89% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "2022 reads; of these:\r\n",
      "  2022 (100.00%) were paired; of these:\r\n",
      "    1892 (93.57%) aligned concordantly 0 times\r\n",
      "    78 (3.86%) aligned concordantly exactly 1 time\r\n",
      "    52 (2.57%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    1892 pairs aligned concordantly 0 times; of these:\r\n",
      "      1 (0.05%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    1891 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      3782 mates make up the pairs; of these:\r\n",
      "        3776 (99.84%) aligned 0 times\r\n",
      "        2 (0.05%) aligned exactly 1 time\r\n",
      "        4 (0.11%) aligned >1 times\r\n",
      "6.63% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "974 reads; of these:\r\n",
      "  974 (100.00%) were paired; of these:\r\n",
      "    524 (53.80%) aligned concordantly 0 times\r\n",
      "    244 (25.05%) aligned concordantly exactly 1 time\r\n",
      "    206 (21.15%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    524 pairs aligned concordantly 0 times; of these:\r\n",
      "      7 (1.34%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    517 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      1034 mates make up the pairs; of these:\r\n",
      "        1020 (98.65%) aligned 0 times\r\n",
      "        2 (0.19%) aligned exactly 1 time\r\n",
      "        12 (1.16%) aligned >1 times\r\n",
      "47.64% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "2604271 reads; of these:\r\n",
      "  2604271 (100.00%) were paired; of these:\r\n",
      "    245197 (9.42%) aligned concordantly 0 times\r\n",
      "    1521101 (58.41%) aligned concordantly exactly 1 time\r\n",
      "    837973 (32.18%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    245197 pairs aligned concordantly 0 times; of these:\r\n",
      "      20216 (8.24%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    224981 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      449962 mates make up the pairs; of these:\r\n",
      "        399028 (88.68%) aligned 0 times\r\n",
      "        14651 (3.26%) aligned exactly 1 time\r\n",
      "        36283 (8.06%) aligned >1 times\r\n",
      "92.34% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "\r\n",
      "gzip: /srv/scratch/training_camp/tc2017/user1/analysis//trimmed/cln3-SCD-Rep2_R1_001.trimmed.fastq.gz: invalid compressed data--crc error\r\n",
      "\r\n",
      "gzip: /srv/scratch/training_camp/tc2017/user1/analysis//trimmed/cln3-SCD-Rep2_R1_001.trimmed.fastq.gz: invalid compressed data--length error\r\n",
      "Error, fewer reads in file specified with -2 than in file specified with -1\r\n",
      "terminate called after throwing an instance of 'int'\r\n",
      "bowtie2-align died with signal 6 (ABRT) (core dumped)\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "3831917 reads; of these:\r\n",
      "  3831917 (100.00%) were paired; of these:\r\n",
      "    278371 (7.26%) aligned concordantly 0 times\r\n",
      "    2271314 (59.27%) aligned concordantly exactly 1 time\r\n",
      "    1282232 (33.46%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    278371 pairs aligned concordantly 0 times; of these:\r\n",
      "      39481 (14.18%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    238890 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      477780 mates make up the pairs; of these:\r\n",
      "        400104 (83.74%) aligned 0 times\r\n",
      "        21606 (4.52%) aligned exactly 1 time\r\n",
      "        56070 (11.74%) aligned >1 times\r\n",
      "94.78% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "2993780 reads; of these:\r\n",
      "  2993780 (100.00%) were paired; of these:\r\n",
      "    169623 (5.67%) aligned concordantly 0 times\r\n",
      "    1476771 (49.33%) aligned concordantly exactly 1 time\r\n",
      "    1347386 (45.01%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    169623 pairs aligned concordantly 0 times; of these:\r\n",
      "      23181 (13.67%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    146442 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      292884 mates make up the pairs; of these:\r\n",
      "        221351 (75.58%) aligned 0 times\r\n",
      "        16125 (5.51%) aligned exactly 1 time\r\n",
      "        55408 (18.92%) aligned >1 times\r\n",
      "96.30% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "3755622 reads; of these:\r\n",
      "  3755622 (100.00%) were paired; of these:\r\n",
      "    192898 (5.14%) aligned concordantly 0 times\r\n",
      "    2169075 (57.76%) aligned concordantly exactly 1 time\r\n",
      "    1393649 (37.11%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    192898 pairs aligned concordantly 0 times; of these:\r\n",
      "      29881 (15.49%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    163017 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      326034 mates make up the pairs; of these:\r\n",
      "        254604 (78.09%) aligned 0 times\r\n",
      "        17587 (5.39%) aligned exactly 1 time\r\n",
      "        53843 (16.51%) aligned >1 times\r\n",
      "96.61% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "1732504 reads; of these:\r\n",
      "  1732504 (100.00%) were paired; of these:\r\n",
      "    88640 (5.12%) aligned concordantly 0 times\r\n",
      "    975962 (56.33%) aligned concordantly exactly 1 time\r\n",
      "    667902 (38.55%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    88640 pairs aligned concordantly 0 times; of these:\r\n",
      "      13989 (15.78%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    74651 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      149302 mates make up the pairs; of these:\r\n",
      "        114531 (76.71%) aligned 0 times\r\n",
      "        7838 (5.25%) aligned exactly 1 time\r\n",
      "        26933 (18.04%) aligned >1 times\r\n",
      "96.69% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "3727086 reads; of these:\r\n",
      "  3727086 (100.00%) were paired; of these:\r\n",
      "    224302 (6.02%) aligned concordantly 0 times\r\n",
      "    2426520 (65.11%) aligned concordantly exactly 1 time\r\n",
      "    1076264 (28.88%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    224302 pairs aligned concordantly 0 times; of these:\r\n",
      "      34513 (15.39%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    189789 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      379578 mates make up the pairs; of these:\r\n",
      "        311200 (81.99%) aligned 0 times\r\n",
      "        24943 (6.57%) aligned exactly 1 time\r\n",
      "        43435 (11.44%) aligned >1 times\r\n",
      "95.83% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "4239526 reads; of these:\r\n",
      "  4239526 (100.00%) were paired; of these:\r\n",
      "    334580 (7.89%) aligned concordantly 0 times\r\n",
      "    3058023 (72.13%) aligned concordantly exactly 1 time\r\n",
      "    846923 (19.98%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    334580 pairs aligned concordantly 0 times; of these:\r\n",
      "      57209 (17.10%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    277371 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      554742 mates make up the pairs; of these:\r\n",
      "        488626 (88.08%) aligned 0 times\r\n",
      "        27176 (4.90%) aligned exactly 1 time\r\n",
      "        38940 (7.02%) aligned >1 times\r\n",
      "94.24% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "4560011 reads; of these:\r\n",
      "  4560011 (100.00%) were paired; of these:\r\n",
      "    180206 (3.95%) aligned concordantly 0 times\r\n",
      "    2937446 (64.42%) aligned concordantly exactly 1 time\r\n",
      "    1442359 (31.63%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    180206 pairs aligned concordantly 0 times; of these:\r\n",
      "      49490 (27.46%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    130716 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      261432 mates make up the pairs; of these:\r\n",
      "        167283 (63.99%) aligned 0 times\r\n",
      "        28805 (11.02%) aligned exactly 1 time\r\n",
      "        65344 (24.99%) aligned >1 times\r\n",
      "98.17% overall alignment rate\r\n",
      "[samopen] SAM header is present: 17 sequences.\r\n",
      "4376854 reads; of these:\r\n",
      "  4376854 (100.00%) were paired; of these:\r\n",
      "    169693 (3.88%) aligned concordantly 0 times\r\n",
      "    2813168 (64.27%) aligned concordantly exactly 1 time\r\n",
      "    1393993 (31.85%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    169693 pairs aligned concordantly 0 times; of these:\r\n",
      "      37019 (21.82%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    132674 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      265348 mates make up the pairs; of these:\r\n",
      "        181304 (68.33%) aligned 0 times\r\n",
      "        29265 (11.03%) aligned exactly 1 time\r\n",
      "        54779 (20.64%) aligned >1 times\r\n",
      "97.93% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "for trimmed_fq1 in ${TRIMMED_DIR}*_R1*fastq.gz; do\n",
    "\n",
    "    trimmed_fq2=$(echo $trimmed_fq1 | sed -e 's/_R1/_R2/')\n",
    "    \n",
    "    bam=$(echo \"${ALIGNMENT_DIR}${trimmed_fq1##*/}\" | sed -e 's/.fastq.gz/.bam/')\n",
    "    bowtie2 -X2000 --mm --threads 10 -x $bowtie_index -1 $trimmed_fq1 -2 $trimmed_fq2 | samtools view -bS - > $bam        \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Finding duplicate reads and alignment filtering\n",
    "\n",
    "During sequencing, we perform PCR, which can lead to duplicate reads. In many kinds of DNA sequencing, we want to remove duplicates so that we don't double-count signal originating from the same molecule.\n",
    "\n",
    "To do so, we use an algorithm called `sambamba` that looks for reads that mapped to exactly the same places in the genome. We also need to sort the aligned files before we can mark duplicates, since we need reads aligned to the same position to be next to each other in the file.\n",
    "\n",
    "Bowtie2 also sets certian labels (or \"flags\") in the resulting alignment file to indicate information like the score of the alignment, the orientation of both mates of the fragment, and other details.\n",
    "\n",
    "We can use these flags as a way to discard low-quality reads. [This website](https://broadinstitute.github.io/picard/explain-flags.html) provides a convenient way to interpret the meaning of these bitwise flags; for conveninece they can be encoded as numbers.\n",
    "\n",
    "Here, we want to filter reads that fall into any of the following categories:\n",
    "- the read wasn't mapped to the genome\n",
    "- the read's mate wasn't mapped to the genome\n",
    "- the alignment reported is not the primary alignment (it is a \"runner-up\" alignment)\n",
    "- the read was marked as \"low-quality\" by the sequencer software\n",
    "- the read has a mapping quality less than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 1455280 end pairs\r\n",
      "     and 15026 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 221 ms\r\n",
      "  found 956072 duplicates\r\n",
      "collected list of positions in 0 min 10 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 17 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 2883323 end pairs\r\n",
      "     and 24935 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 420 ms\r\n",
      "  found 1728829 duplicates\r\n",
      "collected list of positions in 0 min 18 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 32 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 543951 end pairs\r\n",
      "     and 4254 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 75 ms\r\n",
      "  found 153659 duplicates\r\n",
      "collected list of positions in 0 min 2 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 5 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3071531 end pairs\r\n",
      "     and 27390 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 442 ms\r\n",
      "  found 1528076 duplicates\r\n",
      "collected list of positions in 0 min 16 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 31 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3658944 end pairs\r\n",
      "     and 34880 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 519 ms\r\n",
      "  found 1738693 duplicates\r\n",
      "collected list of positions in 0 min 23 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 40 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3931895 end pairs\r\n",
      "     and 41069 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 560 ms\r\n",
      "  found 1951272 duplicates\r\n",
      "collected list of positions in 0 min 24 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 44 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 172499 end pairs\r\n",
      "     and 972 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 26 ms\r\n",
      "  found 44911 duplicates\r\n",
      "collected list of positions in 0 min 0 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 1 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3833173 end pairs\r\n",
      "     and 38017 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 550 ms\r\n",
      "  found 1720072 duplicates\r\n",
      "collected list of positions in 0 min 22 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 41 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 132 end pairs\r\n",
      "     and 4 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 0 ms\r\n",
      "  found 6 duplicates\r\n",
      "collected list of positions in 0 min 0 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 0 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 463 end pairs\r\n",
      "     and 2 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 0 ms\r\n",
      "  found 4 duplicates\r\n",
      "collected list of positions in 0 min 0 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 0 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 2393948 end pairs\r\n",
      "     and 21618 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 340 ms\r\n",
      "  found 1023704 duplicates\r\n",
      "collected list of positions in 0 min 13 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 25 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 1461854 end pairs\r\n",
      "     and 13221 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 212 ms\r\n",
      "  found 572206 duplicates\r\n",
      "collected list of positions in 0 min 5 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 12 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3615639 end pairs\r\n",
      "     and 32452 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 525 ms\r\n",
      "  found 1728134 duplicates\r\n",
      "collected list of positions in 0 min 21 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 39 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 2869215 end pairs\r\n",
      "     and 27779 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 421 ms\r\n",
      "  found 1747654 duplicates\r\n",
      "collected list of positions in 0 min 19 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 32 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3614765 end pairs\r\n",
      "     and 27110 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 518 ms\r\n",
      "  found 1881724 duplicates\r\n",
      "collected list of positions in 0 min 20 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 36 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 1669000 end pairs\r\n",
      "     and 12477 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 236 ms\r\n",
      "  found 720993 duplicates\r\n",
      "collected list of positions in 0 min 10 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 18 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3553952 end pairs\r\n",
      "     and 35068 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 493 ms\r\n",
      "  found 1381273 duplicates\r\n",
      "collected list of positions in 0 min 18 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 36 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 3977362 end pairs\r\n",
      "     and 35702 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 550 ms\r\n",
      "  found 1193148 duplicates\r\n",
      "collected list of positions in 0 min 22 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 42 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 4456061 end pairs\r\n",
      "     and 40617 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 635 ms\r\n",
      "  found 2079803 duplicates\r\n",
      "collected list of positions in 0 min 25 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 45 sec\r\n",
      "finding positions of the duplicate reads in the file...\r\n",
      "  sorted 4265348 end pairs\r\n",
      "     and 41708 single ends (among them 0 unmatched pairs)\r\n",
      "  collecting indices of duplicate reads...   done in 598 ms\r\n",
      "  found 1824874 duplicates\r\n",
      "collected list of positions in 0 min 25 sec\r\n",
      "marking duplicates...\r\n",
      "total time elapsed: 0 min 45 sec\r\n"
     ]
    }
   ],
   "source": [
    "for bam_file in ${ALIGNMENT_DIR}*.trimmed.bam; do\n",
    "\n",
    "    bam_file_sorted=$(echo $bam_file | sed -e 's/.bam/.sorted.bam/')\n",
    "    bam_file_dup=$(echo $bam_file | sed -e 's/.bam/.sorted.dup.bam/')\n",
    "    nodup_bam_file=$(echo $bam_file | sed -e 's/.bam/.nodup.bam/')\n",
    "    \n",
    "    # Sort and remove duplicates\n",
    "    sambamba sort -m 4G -t 40 -u $bam_file \n",
    "    sambamba markdup -l 0 -t 40 $bam_file_sorted $bam_file_dup\n",
    "    samtools view -F 1804 -f 2 -q 30 -b $bam_file_dup  > $nodup_bam_file\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Peak calling\n",
    "\n",
    "Now that we've aligned our reads to the genome and filtered the alignments, we want to identify areas of locally enriched signals, or \"peaks\".\n",
    "\n",
    "For ATAC-seq, peaks correspond to accessible regions. They can include promoters, enhancers, and other regulatory regions.\n",
    "\n",
    "We'll call peaks using [MACS2](http://liulab.dfci.harvard.edu/MACS/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a directory to store the tagAlign data \n",
    "TAGALIGN_DIR=\"${ANALYSIS_DIR}tagAlign/\"\n",
    "[[ ! -d $TAGALIGN_DIR ]] && mkdir -p \"$TAGALIGN_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a directory to store the MACS peaks \n",
    "PEAKS_DIR=\"${ANALYSIS_DIR}peaks/\"\n",
    "[[ ! -d $PEAKS_DIR ]] && mkdir -p \"$PEAKS_DIR\"\n",
    "echo $PEAKS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SacCer3GenSz=12157105  # The sum of the sizes of the chromosomes in the SacCer3 genome\n",
    "\n",
    "Macs2PvalThresh=\"0.05\"  # The p-value threshold for calling peaks \n",
    "\n",
    "Macs2SmoothWindow=150  # The window size to smooth alignment signal over\n",
    "Macs2ShiftSize=$(python -c \"print(int(${Macs2SmoothWindow}/2))\")\n",
    "\n",
    "for nodup_bam_file in ${ALIGNMENT_DIR}*.nodup.bam; do\n",
    "    \n",
    "    # First, we need to convert each bam to a .tagAlign,\n",
    "    # which just contains the start/end positions of each read:\n",
    "    \n",
    "    tagalign_file=$TAGALIGN_DIR$(echo $(basename $nodup_bam_file) | sed -e 's/.bam/.tagAlign.gz/')\n",
    "    #bedtools bamtobed -i $nodup_bam_file | awk 'BEGIN{OFS=\"\\t\"}{$4=\"N\";$5=\"1000\";print $0}' | gzip -c > $tagalign_file\n",
    "    \n",
    "    # Now, we can run MACS:\n",
    "    output_prefix=$PEAKS_DIR$(echo $(basename $tagalign_file)| sed -e 's/.tagAlign.gz//')\n",
    "     macs2 callpeak \\\n",
    "        -t $tagalign_file -f BED -n $output_prefix -g \"$SacCer3GenSz\" -p $Macs2PvalThresh \\\n",
    "        --nomodel --shift -$Macs2ShiftSize --extsize $Macs2SmoothWindow -B --SPMR --keep-dup all --call-summits\n",
    "\n",
    "    #We also generate a fold change file comparing the sample to the control(DMSO)\n",
    "    macs2 bdgcmp -t $output_prefix\\_treat_pileup.bdg -c $output_prefix\\_control_lambda.bdg -o $output_prefix\\_FE.bdg -m FE\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we merge the peaks across all conditions to create a master list of peaks for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $PEAKS_DIR\n",
    "#concatenate all .narrowPeak files together \n",
    "cat *narrowPeak > all.peaks.bed \n",
    "\n",
    "#sort the concatenated file \n",
    "bedtools sort -i all.peaks.bed > all.peaks.sorted.bed \n",
    "\n",
    "#merge the sorted, concatenated fileto join overlapping peaks \n",
    "bedtools merge -i all.peaks.sorted.bed | sed -n 'p;='  | paste -d\"\\t\" - - >  all_merged.peaks.bed\n",
    "gzip -f all_merged.peaks.bed \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
